- [workflow에서 s3 사용하기](https://argoproj.github.io/argo-workflows/configure-artifact-repository/#configuring-aws-s3)
- ```sh
  # 버킷 생성
  $> aws s3 mb s3://$mybucket --region {region}
  
  # s3 bucket을 사용할 수 있는 iam 계정 생성
  $> aws iam create-user --user-name $mybucket-user
  
  # 생성한 iam 계정에 s3 권한 설정
  $> aws iam put-user-policy --user-name $mybucket-user --policy-name $mybucket-policy --policy-document policy.json
  
  # iam 계정의 access-key 생성
  $> aws iam create-access-key --user-name $mybucket-user > access-key.json
  ```
- policy.json 👇
  ```json
  {
     "Version":"2012-10-17",
     "Statement":[
        {
           "Effect":"Allow",
           "Action":[
              "s3:PutObject",
              "s3:GetObject"
           ],
           "Resource":"arn:aws:s3:::$mybucket/*"
        }
     ]
  }
  ```
- artifact로 s3 사용 시에는 다음과 같은 값을 추가해주면 됨
  ```yaml
   artifacts:
        - name: message
          path: /tmp/hello-world.txt
          s3:
            accessKeySecret:
              key: accesskey
              name: mkp-artifacts-secret
            bucket: mkp-artifacts
            endpoint: s3.amazonaws.com
            key: path/s3-result.txt.tgz
            region: ap-northeast-2
            secretKeySecret:
              key: secretkey
              name: mkp-artifacts-secret
  ```
	- aws에서 받은 access key를 secret으로 관리
		- ```sh
		  $> kubectl create secret generic {secret_name} --from-literal=accesskey={ACCESS_KEY} --from-literal=secretkey={SECRET_KEY}
		  ```
- workflow 생성
	- s3에 파일을 저장하기 위해서는 **파일 쓰기**로 파일을 생성해야함
	- ```yaml
	  # script templates provide a way to run arbitrary snippets of code
	  # in any language, to produce a output "result" via the standard out
	  # of the template. Results can then be referenced using the variable,
	  # {{steps.<stepname>.outputs.result}}, and used as parameter to other
	  # templates, and in 'when', and 'withParam' clauses.
	  # This example demonstrates the use of a python script to
	  # generate a random number which is printed in the next step.
	  apiVersion: argoproj.io/v1alpha1
	  kind: Workflow
	  metadata:
	    generateName: scripts-python-
	  spec:
	    entrypoint: python-script-example
	    templates:
	    - name: python-script-example
	      steps:
	      - - name: generate
	          template: save-crawling-data-s3
	      - - name: print
	          template: print-message
	          arguments:
	            parameters:
	            - name: message
	              value: "{{steps.generate.outputs.result}}"
	  
	    - name: save-crawling-data-s3
	      script:
	        image: 293315485843.dkr.ecr.ap-northeast-2.amazonaws.com/kkr/crawler-python:0.1.0
	        command: [python]
	        source: |
	          import requests
	          import json
	          
	          API_KEY = "o5_V5xLXI8uBy0JvElLzVVuccpskDHro"
	          ENDPOINT = f'https://eth-mainnet.alchemyapi.io/v2/{API_KEY}'
	          
	          params = {
	                      "jsonrpc":"2.0",
	                      "method":"eth_getBlockByNumber",
	                      "params":["0x1b4", True],
	                      "id":0
	                  }
	          
	          res = requests.post(ENDPOINT, json=params)
	          print(json.dumps(res.json()))
	          with open('/tmp/hello-world.txt', 'w') as f:
	            f.write(json.dumps(res.json()))
	      outputs:
	        artifacts:
	        - name: message
	          path: /tmp/hello-world.txt
	          s3:
	            accessKeySecret:
	              key: accesskey
	              name: mkp-artifacts-secret
	            bucket: mkp-artifacts
	            endpoint: s3.amazonaws.com
	            key: path/s3-result.txt.tgz
	            region: ap-northeast-2
	            secretKeySecret:
	              key: secretkey
	              name: mkp-artifacts-secret
	    - name: print-message
	      inputs:
	        parameters:
	        - name: message
	      container:
	        image: alpine:latest
	        command: [sh, -c]
	        args: ["echo result was: {{inputs.parameters.message}}"]
	  
	  ```